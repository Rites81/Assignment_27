{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "547b74d9",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7c3d8d",
   "metadata": {},
   "source": [
    "Q1. Explain the concept of R-squared in linear regression models. How is it calculated, and what does it represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa753a5b",
   "metadata": {},
   "source": [
    "Answer: R-square is a astataical measure that represents the proportion of the variance in the dependent variable that is predictable from the dependent variabe in a regression model. it Quantifies the goodness of fit of the model. IT is a statistical measure that determines how well a regression model predicts the outcome of observed data.\n",
    "\n",
    "Calculation\n",
    "R^2 = 1 - {RSS}/{TSS}\n",
    "\n",
    "R^2\t=\tcoefficient of determination\n",
    "RSS\t=\tsum of squares of residuals\n",
    "TSS\t=\ttotal sum of squares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca923c8",
   "metadata": {},
   "source": [
    "Q2. Define adjusted R-squared and explain how it differs from the regular R-squared. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605cfe48",
   "metadata": {},
   "source": [
    "Answer: Adjusted r Square is a modified version of R-square that has been           adjusted for the number of predictors in the model.The adjusted R-           squared increases when the new term improves the model more than            would be expected by chance. It decreases when a predictor improves          the model by less than expected.\n",
    "Formula:\n",
    "\n",
    "Adjusted R-Squared = 1-[(1 – R2) (n – 1)/ (n – k – 1)]\n",
    "\n",
    "\n",
    "\n",
    "R-squared (R2) and adjusted R-squared are both used to evaluate the goodness of fit of a regression model. R2 represents the proportion of the variance in the dependent variable explained by the independent variables. Adjusted R-squared considers the number of predictors in the model and penalizes excessive variables, providing a more accurate measure of the model’s goodness of fit, especially with multiple predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaf7a72",
   "metadata": {},
   "source": [
    "Q3. When is it more appropriate to use adjusted R-squared?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4d08ef",
   "metadata": {},
   "source": [
    "Adjusted R-squared is more appropriate when comparing models or selecting predictors, helping to balance model simplicity with explanatory power, especially in situations with different numbers of predictors or smaller datasets, Checking Model's Accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40007abc",
   "metadata": {},
   "source": [
    "Q4. What are RMSE, MSE, and MAE in the context of regression analysis? How are these metrics calculated, and what do they represent?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73db827",
   "metadata": {},
   "source": [
    "MAE - The Mean absolute error represents the average of the absolute difference between the actual and predicted values in the dataset. It measures the average of the residuals in the dataset.\n",
    "\n",
    "                   MAE = sum of absolute error/Number of Predictions\n",
    "                   \n",
    "MSE - Mean Squared Error represents the average of the squared difference between the original and predicted values in the data set. It measures the variance of the residuals.\n",
    "\n",
    "                   MSE = sum of square error/Number of Predictions\n",
    "                   \n",
    "RMSE - Root Mean Squared Error is the square root of Mean Squared error. It measures the standard deviation of residuals.\n",
    "\n",
    "                   RootMeanSquaredError(RMSE)= square of MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38bd56d",
   "metadata": {},
   "source": [
    "Q5. Discuss the advantages and disadvantages of using RMSE, MSE, and MAE as evaluation metrics in regression analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863083c1",
   "metadata": {},
   "source": [
    "Root Mean Squared Error (RMSE):\n",
    "\n",
    "Advantages:\n",
    "\n",
    "Emphasizes accuracy by penalizing larger errors more.\n",
    "Results in values with the same units as the dependent variable, aiding interpretation.\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "Sensitive to outliers, which can disproportionately impact the metric.\n",
    "May over-penalize large errors in situations where a more balanced view is needed.\n",
    "\n",
    "Mean Squared Error (MSE):\n",
    "\n",
    "Advantages:\n",
    "\n",
    "Measures average squared differences, emphasizing larger errors.\n",
    "Mathematically convenient for optimization algorithms.\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "Sensitive to outliers, potentially providing a skewed view of model performance.\n",
    "Values are not in the same units as the dependent variable, making direct interpretation challenging.\n",
    "\n",
    "Mean Absolute Error (MAE):\n",
    "\n",
    "Advantages:\n",
    "\n",
    "Robust to outliers, offering a more balanced measure of model performance.\n",
    "Gives equal weight to all errors, providing a straightforward interpretation.\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "May not sufficiently penalize larger errors, potentially underestimating their impact.\n",
    "Values are not in the same units as the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe4e729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9407265",
   "metadata": {},
   "source": [
    "Q6. Explain the concept of Lasso regularization. How does it differ from Ridge regularization, and when is it more appropriate to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4bc2c4",
   "metadata": {},
   "source": [
    "Lasso regularization is a technique used in linear regression to prevent overfitting and improve the model's generalization performance. Lasso uses an L1 penalty, which is the sum of the absolute values of the coefficients.\n",
    "\n",
    "Differences from Ridge Regularization:\n",
    "\n",
    "##### Type of Penalty:\n",
    "\n",
    "Lasso uses an L1 penalty, which is the sum of the absolute values of the coefficients.\n",
    "\n",
    "Ridge regularization uses an L2 penalty, which is the sum of the squared values of the coefficients.\n",
    "\n",
    "##### Effect on Coefficients:\n",
    "\n",
    "Lasso tends to produce sparse models by driving some coefficients to exactly zero, effectively performing feature selection.\n",
    "\n",
    "Ridge generally shrinks the coefficients towards zero but rarely sets them exactly to zero.\n",
    "\n",
    "##### Handling Multicollinearity:\n",
    "\n",
    "Lasso is effective in handling multicollinearity by selecting one variable among highly correlated variables and pushing the coefficients of the others to zero.\n",
    "\n",
    "Ridge handles multicollinearity by reducing the impact of all variables, but it doesn't lead to variable selection.\n",
    "\n",
    "\n",
    "When to Use Lasso:\n",
    "\n",
    "Feature Selection:\n",
    "\n",
    "When there is a large number of features, and you want to identify and use only the most important ones.\n",
    "\n",
    "Sparse Models:\n",
    "\n",
    "When you prefer a model with fewer non-zero coefficients, making it more interpretable and efficient.\n",
    "\n",
    "Handling Multicollinearity:\n",
    "\n",
    "When dealing with highly correlated predictors, as Lasso can choose one of them and set others to zero.\n",
    "\n",
    "Trade-off with Ridge:\n",
    "\n",
    "When a combination of feature selection and regularization is desired, Lasso can be used in combination with Ridge in Elastic Net regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8587959",
   "metadata": {},
   "source": [
    "Q7. How do regularized linear models help to prevent overfitting in machine learning? Provide an example to illustrate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf5acec",
   "metadata": {},
   "source": [
    "Regularization refers to techniques that are used to calibrate machine learning models in order to minimize the adjusted loss function and prevent overfitting or underfitting. Using Regularization, we can fit our machine learning model appropriately on a given test set and hence reduce the errors in it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd929719",
   "metadata": {},
   "source": [
    "Q8. Discuss the limitations of regularized linear models and explain why they may not always be the best choice for regression analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273d6dda",
   "metadata": {},
   "source": [
    "Feature Selection Bias:\n",
    "\n",
    "Lasso regularization can exclude important features by setting coefficients exactly to zero.\n",
    "Sensitivity to Scaling:\n",
    "\n",
    "Regularized models are sensitive to feature scaling, requiring standardization or normalization.\n",
    "Difficulty in Choosing Hyperparameters:\n",
    "\n",
    "Selecting appropriate hyperparameters, like the regularization strength, can be challenging and affects model performance.\n",
    "Not Always Interpretable:\n",
    "\n",
    "Coefficients may become less interpretable, especially with L1 regularization (Lasso).\n",
    "Assumption of Linearity:\n",
    "\n",
    "Assumes a linear relationship between predictors and the response, limiting effectiveness in highly nonlinear scenarios.\n",
    "Limited Handling of Outliers:\n",
    "\n",
    "Outliers can impact model performance as regularization may not robustly handle extreme values.\n",
    "Computational Complexity:\n",
    "\n",
    "Solving regularized regression problems can be computationally expensive, particularly for large datasets.\n",
    "\n",
    "\n",
    "#### When Regularized Linear Models May Not Be the Best Choice:\n",
    "\n",
    "Small Datasets:\n",
    "\n",
    "Regularization may lead to unstable models with limited data.\n",
    "Highly Nonlinear Relationships:\n",
    "\n",
    "In scenarios where the true relationship is highly nonlinear, regularized models may struggle.\n",
    "Interpretability Prioritization:\n",
    "\n",
    "When interpretability is crucial and simpler models without regularization are preferred.\n",
    "Noisy Data:\n",
    "\n",
    "Regularized models may struggle to distinguish signal from noise in the presence of significant data noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99a62b3",
   "metadata": {},
   "source": [
    "Q9. You are comparing the performance of two regression models using different evaluation metrics. \n",
    "Model A has an RMSE of 10, while Model B has an MAE of 8. Which model would you choose as the better performer, and why? Are there any limitations to your choice of metric?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8549a31",
   "metadata": {},
   "source": [
    "Evaluation of Models A and B:\n",
    "\n",
    "Model A (RMSE: 10):\n",
    "\n",
    "Indicates the average squared difference between predicted and actual values.\n",
    "Penalizes larger errors more heavily.\n",
    "Model B (MAE: 8):\n",
    "\n",
    "Represents the average absolute difference between predicted and actual values.\n",
    "Treats all errors equally, irrespective of size.\n",
    "Choice and Limitations:\n",
    "\n",
    "Better Performer:\n",
    "\n",
    "Depends on the specific goals and characteristics of the problem.\n",
    "Considerations:\n",
    "\n",
    "If larger errors are more critical, favor Model A with RMSE.\n",
    "If equal weighting of all errors is desired, Model B with MAE might be preferable.\n",
    "Limitations:\n",
    "\n",
    "RMSE is sensitive to outliers and can be influenced by the scale of the dependent variable.\n",
    "MAE may not penalize larger errors enough and might be less sensitive to extreme values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a9fe6b",
   "metadata": {},
   "source": [
    "Q10. You are comparing the performance of two regularized linear models using different types of regularization. Model A uses Ridge regularization with a regularization parameter of 0.1, while Model B uses Lasso regularization with a regularization parameter of 0.5. Which model would you choose as the better performer, and why? Are there any trade-offs or limitations to your choice of regularization method?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ea0b3f",
   "metadata": {},
   "source": [
    "Evaluation of Regularized Models A and B:\n",
    "\n",
    "Model A (Ridge, λ=0.1):\n",
    "\n",
    "Ridge regularization with an L2 penalty.\n",
    "Encourages smaller but non-zero coefficients for all features.\n",
    "Model B (Lasso, λ=0.5):\n",
    "\n",
    "Lasso regularization with an L1 penalty.\n",
    "May lead to some coefficients being exactly zero, performing feature selection.\n",
    "Choice and Considerations:\n",
    "\n",
    "Better Performer:\n",
    "\n",
    "Depends on the specific goals and characteristics of the problem.\n",
    "Considerations:\n",
    "\n",
    "If feature selection is desired, and some features can be omitted without sacrificing performance, Lasso (Model B) might be preferable.\n",
    "If all features are deemed important, Ridge (Model A) may provide more stable results.\n",
    "Trade-offs and Limitations:\n",
    "\n",
    "Ridge (Model A):\n",
    "\n",
    "Less likely to drive coefficients exactly to zero, providing a more stable model.\n",
    "May not perform well in situations where some features are truly irrelevant.\n",
    "Lasso (Model B):\n",
    "\n",
    "Performs feature selection by setting some coefficients to exactly zero, leading to a more interpretable and potentially simpler model.\n",
    "Can struggle with highly correlated features, selecting only one among them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8dd929",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
